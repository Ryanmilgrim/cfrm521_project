{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crypto Currency and Portfolio Construction\n",
    "\n",
    "- Ryan Milgrim and Roo Fernando\n",
    "- University of Washington\n",
    "- CFRM 521: Machine Learning\n",
    "- June, 3, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Project Design [20 Points]\n",
    "\n",
    "- Clear and Percise Problem Statement\n",
    "- Reasonable Project Goal\n",
    "- Extra credit of up to 10 points will be given for innovative content\n",
    "\n",
    "#### Problem Statement\n",
    "\n",
    "Cryptocurrency markets, first introduced in 2009, have seen widespread adoption, with two countries now recognizing cryptocurrencies as legal tender. Despite their speculative nature, the popularity of these digital assets continues to grow globally. Traditional investment strategies are typically grounded in economic fundamentals such as company earnings and market interest rates. However, applying these principles to cryptocurrencies is challenging due to their decentralized nature, lack of ties to any single entity, and extreme price volatility. This has made constructing and managing cryptocurrency portfolios particularly difficult for traditional investors.\n",
    "\n",
    "In this project, we aim to develop and demonstrate the application of machine learning methods to construct cryptocurrency strategies that improve returns and reduce the risks associated with these investments. By leveraging these advanced techniques, we seek to provide investors with tools to navigate the highly volatile cryptocurrency markets more effectively, thereby enhancing their ability to make informed investment decisions.\n",
    "\n",
    "#### Project Goal\n",
    "\n",
    "The goal of our project is to develop a machine learning model capable of dynamically adjusting a cryptocurrency portfolio using historical prices and additional derived features. This model will either forecast expected prices or returns for our selected cryptocurrencies or suggest optimal allocations among these currencies. To evaluate the utility of these methods, we will implement a systematic investment process based on the modelâ€™s outputs and compare its performance against naive portfolio construction methods, such as a buy-and-hold strategy with perfect foresight of future returns (a capability our methods will not assume). If our model can achieve out-of-sample returns that exceed those of any individual cryptocurrency, it would demonstrate that our approach enables investors to make more informed and effective decisions in the cryptocurrency domain.\n",
    "\n",
    "### 2. Data Processing and Feature Engineering  [25 Points]\n",
    "\n",
    "#### Reliable and relevant data sources\n",
    "\n",
    "The data we will be using for our analysis can be found here: <a href=\"https://www.kaggle.com/code/adityamhaske/crypto-currencies-price-analysis\">Kaggle - Crypto Currencies Price Analysis</a>. We have consolidated the four CSV files into a single data.csv file to streamline our notebook. \n",
    "\n",
    "The dataset includes historical open, high, low, and closing prices for BTC, ETH, LTC, and XRP from January 1, 2018. Our analysis primarily relies on closing prices to calculate daily returns and other features.\n",
    "\n",
    "It's important to note that our dataset contains some missing values due to exchange issues. Instead of discarding these rows, we have opted to fill missing prices with the last known price, as this method minimizes data loss and maintains the integrity of our time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the datafile and format as a time series.\n",
    "data = pd.read_csv('data.csv', index_col=1)\n",
    "data.index = pd.to_datetime(data.index)#, format='mixed')\n",
    "\n",
    "# Format the dataset into features denoted as {Coin}__{Feature}\n",
    "data = data.set_index(['Crypto'], append=True).unstack()\n",
    "data.columns = [f'{coin}__{ohlc}' for ohlc, coin in data.columns.values]\n",
    "\n",
    "# Sorting the timeseries by date and imputing missing values. \n",
    "data.sort_index()\n",
    "data = data.ffill()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reasonable data cleaning and preprocessing\n",
    "\n",
    "For our analysis, we create an additional feature named \"Return\" representing the day of day change in closign price. To ensure that our dataset is formatted well and free of errors, we visualize the dataset with the below code chunk. \n",
    "\n",
    "The code generates a histogram of daily returns and a time series plot of closing prices. Upon reviewing these visualizations, we noticed an unusual pattern in the histogram for XRP. Further inspection revealed that the dataset contains only two decimal places of precision for XRP, which often trades below $1.00. This lack of precision results in XRP frequently showing a 0% daily return.\n",
    "\n",
    "To address this issue, we have decided to exclude XRP from our analysis and focus on the remaining three cryptocurrencies: BTC, ETH, and LTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_returns_and_prices(coin, returns, prices):\n",
    "    \"\"\"Simple Plot Function to visualize the quality of our data\"\"\"\n",
    "\n",
    "    # Making the plot\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    returns.hist(bins=100, ax=ax[0])\n",
    "    prices.plot(ax=ax[1])\n",
    "\n",
    "    # Apply titles\n",
    "    ax[0].set_title('Daily Returns')\n",
    "    ax[1].set_title('Closing Prices')\n",
    "\n",
    "    # Apply Grids for both plots\n",
    "    ax[0].grid(True, alpha=0.7, linestyle='--')\n",
    "    ax[1].grid(True, alpha=0.7, linestyle='--')\n",
    "\n",
    "    # Apply title and layout\n",
    "    fig.suptitle(coin)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the returns and prices for each coin\n",
    "coins = ['BTC', 'ETH', 'LTC', 'XRP']\n",
    "for coin in coins:\n",
    "    coin_returns = f'{coin}__Returns'\n",
    "    coin_prices = f'{coin}__Close'\n",
    "\n",
    "    # Appending the new Returns Feature\n",
    "    data[coin_returns] = data[coin_prices].pct_change()\n",
    "    plot_returns_and_prices(coin, data[coin_returns], data[coin_prices])\n",
    "\n",
    "# Droping XRP due to our concerns about data quality.\n",
    "coins = ['BTC', 'ETH', 'LTC']\n",
    "data = data.drop(columns=[\n",
    "    'XRP__Open',\n",
    "    'XRP__High',\n",
    "    'XRP__Low',\n",
    "    'XRP__Close',\n",
    "    'XRP__Returns',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective feature selection and generation\n",
    "\n",
    "Predicting expectations of the future based on historical open / high / low / close / returns is quite difficult, some would argue impossible without incorpoating additional exogenous data. We did consider incorporating economic variables such as GDP and CPI, however, we have choosen to use technical indicators derived from historical prices instead. The indcators which we utilize are described below:\n",
    "\n",
    "- **Volatility**: Also known as standard deviation, scaled by the window size of *n* days.\n",
    "\n",
    "- **Momentum**: This indicator was developed through our own creativity and its calculation can be seen below. This indicator aims to capture how above or below the closing price is relative to the moving average and volatility.\n",
    "\n",
    "- **RSI**: RSI measures the speed and magnitude of a security's recent price changes, it is used by technical traders to assess weather and asset is overbought, or oversold. Since crypto-currencies don't have any fundamentals, we believe including a very common technical indicator would be useful. \n",
    "\n",
    "<p>Momentum = <sup>(Close - Moving Average)</sup> / <sub>(Moving Average * Volatility)</sub></p>\n",
    "\n",
    "<p>RSI = 100 - <sup> (100)</sup> / <sub>(1 + (Average Gain/ Average loss))</sub></p>\n",
    "\n",
    "\n",
    "We suspect these technical indicators will provide insight into future prices, but this does come with a small cost in terms of data descruction. We considered using a custom transformer class to address the issue of missing data, however our attempts of this led to poor implemtations when it comes to splitting data into training / validation / testing sets. As a result, we will simply drop the first 40 rows of data which contains missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rsi(prices, window=40):\n",
    "    # Calculate the price differences\n",
    "    delta = prices.diff()\n",
    "\n",
    "    # Separate gains and losses\n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = -delta.where(delta < 0, 0)\n",
    "\n",
    "    # Calculate the average gain and loss\n",
    "    avg_gain = gain.rolling(window=window, min_periods=40).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=40).mean()\n",
    "\n",
    "    # Calculate the relative strength (RS)\n",
    "    rs = avg_gain / avg_loss\n",
    "\n",
    "    # Calculate the RSI\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "\n",
    "    return rsi\n",
    "\n",
    "def transform_prices(prices, window=40):\n",
    "    \"\"\"Function to transform prices into volatility and momentum indicators.\"\"\"\n",
    "    features = pd.DataFrame(index=prices.index)\n",
    "\n",
    "    # Creating the new features\n",
    "    features['Returns'] = prices.pct_change()    \n",
    "    features['MovingAverage'] = prices.rolling(window=window).mean()\n",
    "    features['Volatility'] = features['Returns'].rolling(window=window).std() * np.sqrt(window)\n",
    "    features['RSI'] = calculate_rsi(prices)\n",
    "\n",
    "    # Creating the momentum feature\n",
    "    features['Momentum'] = prices - features['MovingAverage']\n",
    "    features['Momentum'] /= features['MovingAverage'] * features['Volatility']\n",
    "\n",
    "    # Droping features which the function should not append\n",
    "    features = features.drop(columns=['MovingAverage', 'Returns'])\n",
    "\n",
    "    # Returning the new features\n",
    "    return features\n",
    "\n",
    "# Using the function to append new features to the data\n",
    "for coin in coins:\n",
    "    features = transform_prices(data[coin + '__Close'])\n",
    "    data = pd.concat([data, features.add_prefix(f'{coin}__')], axis=1)\n",
    "\n",
    "data = data.sort_index(axis=1)\n",
    "data = data.dropna()\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code chunk provides a visual of our indicators against the log of the closing price. We show these charts to provide the reader with insight into how our technical indcators behave overtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the technical indicators for each coin against its closing price.\n",
    "figsize = (10, 7)\n",
    "for coin in coins:\n",
    "\n",
    "    # Plot the technical indicators.\n",
    "    fig, ax = plt.subplots(4, 1, figsize=figsize)\n",
    "    fig.suptitle(coin)\n",
    "\n",
    "    # Plot the log of price, volatility, and momentum.\n",
    "    np.log(data[f'{coin}__Close']).plot(ax=ax[0], title='Log of Closing Price')\n",
    "    data[f'{coin}__Volatility'].plot(ax=ax[1], title='Volatility')\n",
    "    data[f'{coin}__Momentum'].plot(ax=ax[2], title='Momentum')\n",
    "    data[f'{coin}__RSI'].plot(ax=ax[3], title='RSI')\n",
    "\n",
    "    # Apply Grids for all axs\n",
    "    for axi in ax:\n",
    "        axi.grid(True, alpha=0.7, linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Selection and Implementation [30 Points]\n",
    "\n",
    "- Good reasons for choosing models\n",
    "- Reasonable train/test/validation split\n",
    "- Clear model training and tuning process\n",
    "\n",
    "#### Plotting and Analysis Functions\n",
    "\n",
    "For our analysis / results, we have written the below section of functions to abstract away much of the mundane / reusable code to make our project more readable. Please feel free to skip this section if you wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a returns dataframe for analysis\n",
    "returns = pd.DataFrame()\n",
    "for coin in coins:\n",
    "    returns[coin] = data[coin + '__Returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_regimes_and_get_best_portfolios(returns, regimes):\n",
    "    \"\"\"Function to print the average returns of each coin by regime and return portfolio dictionaries.\"\"\"\n",
    "\n",
    "    n_regimes = len(np.unique(regimes))\n",
    "    regime_returns = returns.loc[regimes.index]\n",
    "\n",
    "    # Print the average returns of each coin by regime and make a portfolio for each regime\n",
    "    portfolios_by_regime = {}\n",
    "    for i in range(n_regimes):\n",
    "        average_returns = regime_returns[regimes == i].mean()\n",
    "\n",
    "        print(f'\\n-- {average_returns.idxmax()} Best coin in Regime {i}')\n",
    "        print(average_returns)\n",
    "\n",
    "        # Add the best portfolio for this regime to the dictionary\n",
    "        best_coin_index = average_returns.idxmax()\n",
    "        portfolios_by_regime[i] = [1 if coin == best_coin_index else 0 for coin in average_returns.index]\n",
    "\n",
    "    # Also print out the best coin overall\n",
    "    overall_average_returns = returns.mean()\n",
    "    print(f'\\n-- Best Coin Overall: {overall_average_returns.idxmax()}')\n",
    "\n",
    "    # Create the best overall portfolio\n",
    "    best_coin_index = overall_average_returns.idxmax()\n",
    "    best_overall_portfolio = [1 if coin == best_coin_index else 0 for coin in overall_average_returns.index]\n",
    "    best_overall_portfolio = {i: best_overall_portfolio for i in range(n_regimes)}\n",
    "\n",
    "    return portfolios_by_regime, best_overall_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_portfolio_timeseries(regimes, portfolio_dict, coins):\n",
    "    \"\"\"Function to create a portfolio timeseries from a regime timeseries and portfolio dictionary\"\"\"\n",
    "\n",
    "    # Create a portfolio timeseries\n",
    "    portfolio = pd.DataFrame(np.zeros((len(regimes), len(coins))), index=regimes.index, columns=coins)\n",
    "    for regime, allocation in portfolio_dict.items():\n",
    "        portfolio[regimes == regime] = allocation\n",
    "\n",
    "    return portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_portfolio_backtest(portfolio, benchmark, returns):\n",
    "    \"\"\"Function to plot the cumulative returns of a portfolio and its allocation over time\"\"\"\n",
    "\n",
    "    # Calculate the cumulative returns of the portfolio and benchmark\n",
    "    portfolio_returns = np.sum(returns * portfolio, axis=1)\n",
    "    benchmark_returns = np.sum(returns * benchmark, axis=1)\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(8, 5))\n",
    "\n",
    "    # Plot the cumulative returns of the portfolio and benchmark\n",
    "    ax[0].set_title('Cumulative Returns')\n",
    "    (1 + portfolio_returns).cumprod().plot(ax=ax[0], label='Portfolio')\n",
    "    (1 + benchmark_returns).cumprod().plot(ax=ax[0], label='Benchmark', linestyle='--')\n",
    "    ax[0].grid(True, alpha=0.7, linestyle='--'), ax[0].legend()\n",
    "\n",
    "    # Plot the rolling 30-day volatility of the portfolio and benchmark\n",
    "    ax[1].set_title('Rolling 30-Day Volatility')\n",
    "    portfolio_returns.rolling(window=30).std().plot(ax=ax[1], label='Portfolio')\n",
    "    benchmark_returns.rolling(window=30).std().plot(ax=ax[1], label='Benchmark', linestyle='--')\n",
    "    ax[1].grid(True, alpha=0.7, linestyle='--'), ax[1].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Print out simple Sharpe ratio metrics\n",
    "    portfolio_sharpe = portfolio_returns.mean() / portfolio_returns.std()\n",
    "    benchmark_sharpe = benchmark_returns.mean() / benchmark_returns.std()\n",
    "    print('\\nSharpe Ratio:')\n",
    "    print(f'Model: {portfolio_sharpe:.4f}')\n",
    "    print(f'Benchmark: {benchmark_sharpe:.4f}')\n",
    "\n",
    "    # Create a plot function which plots the portfolio allocations over time\n",
    "    if portfolio_sharpe > benchmark_sharpe:\n",
    "        print('Model Outperformed the benchmark.')\n",
    "    else:\n",
    "        print('Model Failed to beat the benchmark.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_portfolio_allocations(portfolio, benchmark):\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(8, 5))\n",
    "    fig.suptitle('Model and Benchmark Allocations')\n",
    "\n",
    "    # Plot the portfolio allocation\n",
    "    portfolio.plot(ax=ax[0], kind='area', stacked=True)   \n",
    "    ax[0].set_ylim((0, 1)), ax[0].set_ylabel('Portfolio'), ax[0].legend()\n",
    "    ax[0].grid(True, alpha=0.7, linestyle='--')\n",
    "\n",
    "    # Plot the portfolio allocation without x or y axis labels\n",
    "    benchmark.plot(ax=ax[1], kind='area', stacked=True)\n",
    "    ax[1].set_ylim((0, 1)), ax[1].set_ylabel('Benchmark'), ax[1].legend()\n",
    "    ax[1].grid(True, alpha=0.7, linestyle='--')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KMeans Persistent Regime Model\n",
    "\n",
    "For our first model, we will keep things simple and assume that our regimes persist for a single day. This will inform our prediction of which regime will occur on day t+1, and we will also assume that the optimal coin to hold during each regime will remain the same between our training set and our testing set. With these simple assumptions, we can begin to build a portfolio strategy. \n",
    "\n",
    "We will use 60% of the data for training and 40% of the data for testing. Because we have no hyper parameters to tune, we will not concern ourselves with hyper parameter tuning for now. Time series data should not be shuffeled, and the benchmark we hope to beat, is the best returning coin's performance of the testing dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we introduce a simple pipeline which applies a robust scaler to our indicators then fits a kmeans model for n_clusters from 2 through 10 to determine the optimal number of clusters. After our analysis, we found that 2 clusters were optimal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Create the pipeline to only momentum and volatility columns\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('kmeans', KMeans(n_init=10, random_state=42))\n",
    "])\n",
    "\n",
    "# Create an X dataset with only the technical indicators for regime detection\n",
    "technical_indicators = [coin + '__Momentum' for coin in coins]\n",
    "technical_indicators += [coin + '__Volatility' for coin in coins]\n",
    "X = data[technical_indicators]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Fit the pipeline to the for n_clusters = {2 - 10} and record silhouette score.\n",
    "scores = dict()\n",
    "for n in range(2, 11):\n",
    "    pipeline.set_params(kmeans__n_clusters=n)\n",
    "    pipeline.fit(X)\n",
    "    \n",
    "    # Transform data to get cluster labels\n",
    "    labels = pipeline['kmeans'].labels_\n",
    "\n",
    "    # Calculate the silhouette score\n",
    "    score = silhouette_score(X, labels)\n",
    "    scores[n] = score\n",
    "\n",
    "# Refitting the model to our best found parameter\n",
    "n_regimes = 3\n",
    "pipeline.set_params(kmeans__n_clusters=n_regimes)\n",
    "pipeline.fit(X)\n",
    "\n",
    "# Plot the scores\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list(scores.keys()), list(scores.values()), linestyle='--')\n",
    "ax.scatter(list(scores.keys()), list(scores.values()))\n",
    "ax.set_title('Silhouette Score for KMeans')\n",
    "ax.set_xlabel('Number of Clusters')\n",
    "ax.set_ylabel('Silhouette Score')\n",
    "ax.grid(True, alpha=0.7, linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the below plots and metrics, it seems reasonable to believe that our, so far simple, model could be useful in navigating financial markets. Using 2 regimes clustered from our technical indicators, it would indicate that BTC is the best coin to hold 74% of the time but if an investor were to partake in market timing, they may earn more by holding ETH.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a regimes timeseries\n",
    "regimes = pd.Series(pipeline.predict(X), data.index)\n",
    "for coin in coins:\n",
    "\n",
    "    fig, axs = plt.subplots(1, n_regimes, figsize=(2 * n_regimes, 3))\n",
    "    fig.suptitle(f'{coin} Returns by Regime')\n",
    "\n",
    "    # Plot a histogram of each regime with the mean return in the title\n",
    "    for i in range(n_regimes):\n",
    "\n",
    "        # Filtering down to the coin's returns within the regime\n",
    "        regime_returns = data.loc[regimes == i, f'{coin}__Returns']\n",
    "\n",
    "        # Plotting the histogram\n",
    "        regime_returns.hist(bins=100, ax=axs[i])\n",
    "        axs[i].set_title(f'Regime {i}: {regime_returns.mean():.2%}')\n",
    "        axs[i].grid(True, alpha=0.7, linestyle='--')\n",
    "        axs[i].set_xlim((-0.15, 0.15))\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "# Print the number of days in each regime\n",
    "print('\\nDays In:')\n",
    "for i in range(n_regimes):\n",
    "    print(f'Regime {i}: {regimes.value_counts()[i]}')\n",
    "\n",
    "# Print the percentage of time in each regime\n",
    "print('\\nPercentage of Time in:')\n",
    "for i in range(n_regimes):\n",
    "    print(f'Regime {i}: {regimes.value_counts(normalize=True)[i]:.2%}')\n",
    "\n",
    "# Print a transition matrix. The probability of transitioning from regime a to b\n",
    "transition_matrix = pd.crosstab(regimes.shift(), regimes, normalize='index')\n",
    "print('\\nTransition Matrix:')\n",
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "centers = pipeline['kmeans'].cluster_centers_\n",
    "centers = pd.DataFrame(pipeline['scaler'].inverse_transform(centers), columns=technical_indicators)\n",
    "centers.index.name = 'Regime'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "centers.plot(kind='bar', ax=ax)\n",
    "plt.title('Cluster Centers')\n",
    "plt.grid(True, alpha=0.7, linestyle='--')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test = train_test_split(X, test_size=0.4, shuffle=False)\n",
    "\n",
    "# Fit the pipeline to the training set and predict both training and test sets.\n",
    "pipeline.fit(X_train)\n",
    "regimes_train = pd.Series(pipeline.predict(X_train), X_train.index)\n",
    "regimes_test = pd.Series(pipeline.predict(X_test), X_test.index)\n",
    "\n",
    "# Print the transition matrix of the regime test set\n",
    "transition_matrix = pd.crosstab(regimes_test.shift(1), regimes_test, normalize='index')\n",
    "print('\\nTest Transition Matrix:')\n",
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From this print statement, we see that our strategy is to buy BTC in regime 0 and ETH in regime 1.\n",
    "portfolios, _ = analyze_regimes_and_get_best_portfolios(returns, regimes_train)\n",
    "\n",
    "# Create the portfolio timeseries for future testing. It is important to shift 1 day to avoid lookahead bias.\n",
    "portfolios = create_portfolio_timeseries(regimes_test, portfolios, coins).shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# During the testing period, ETH was the best overall coin. So our benchmark to beat is a 100% allocation to ETH during the testing period.\n",
    "_, benchmark = analyze_regimes_and_get_best_portfolios(returns, regimes_test)\n",
    "benchmark = create_portfolio_timeseries(regimes_test, benchmark, coins)\n",
    "\n",
    "# Also make a set of returns for the backtest\n",
    "returns_test = benchmark.align(returns, join='inner')[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the portfolio returns and allocation\n",
    "plot_portfolio_backtest(portfolios, benchmark, returns_test)\n",
    "plot_portfolio_allocations(portfolios, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the results of this backtest, our model managed to out perform the benchmark portfolio (The highest returning coin in the testing data). which means that our model may be able to provide investors with insights into coin timing. \n",
    "\n",
    "It does appear that our model took less risk than the benchmark portfolio, this is due to the model's ability to buy BTC during regimes with higher volatility. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
